---
title: "HarvardX PH125.9x Data Science Capstone Diamond Price"
author: "Stepan Kravtsov"
date: "8 March 2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1. Overview
### Dataset

The dataset used for this project was taken from Kaggle and contains information about price of diamonds and variables that can possibly influence it. The dataset can be found **[here](https://www.kaggle.com/ritikmaheshwari/diamond-price-prediction)**. 

This dataset contains variables such as:

* Price
* Carat
* Cut
* Color
* Clarity
* Depth
* Table
* x
* y
* z


The *price* of the diamond is what we are going to predict.

The *carat* is the mass of the diamond (in carats).

The *cut* is the way in which a diamond is faceted to catch and reflect light. It is measured from Poor to Ideal. In this dataset only the diamonds of cut Fair to Ideal are present.

The *color* refers to how clear or yellow the diamond is. It is measured on a scale from D to Z, where D is the clearest and Z the most yellow. In this dataset only the diamonds of colors J to D are present.

The *clarity* is a qualitative metric that grades the visual appearance of each diamond. It is measured from I (included) to IF (internally flawless).

The *depth* refers to the diamond's measurement from top to bottom. It is measured in percent and is calculated by dividing the diamond's total height by its total width. The depth affects the way a diamond reflects light

The *table* is size of the flat facet on the diamond's surface â€” the large, flat surface facet that you can see when you look at the diamond from above. As the largest facet on a diamond, the table plays a major role in determining how brilliant (sparkly) the diamond is. 

*X*, *Y*, and *Z* are the measurements of the diamond.

### Goal

The goal of this project is to build a model that would predict the diamond's price using the given parameters. The models will be assessed using Mean Absolute Percent Error (MAPE) since we are trying to predict a continuous variable, and this measure will give us the average error we make (in percent).

MAPE is calculated using the formula
\begin{equation}
MAPE=\frac{100\%}{n}\sum_{1}^{n}{\frac{Actual - Predicted}{\left| Actual \right|}}
\end{equation}

The Metrics library will be used to calculate MAPE.
There is no final goal for MAPE. The goal is just to make it as small as possible.

```{r, include=FALSE}
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(readr)) install.packages("readr")
if(!require(ggplot2)) install.packages("ggplot2")
if(!require(dplyr)) install.packages("dplyr")
if(!require(Metrics)) install.packages("Metrics", repos = "http://cran.us.r-project.org")
if(!require(ggthemes)) install.packages("ggthemes")
if(!require(knitr)) install.packages("knitr")
if(!require(dplyr)) install.packages("dplyr")
if(!require(penalized)) install.packages("penalized")
if(!require(gbm)) install.packages("gbm")
library(tidyverse)
library(caret)
library(data.table)
library(readr)
library(ggplot2)
library(dplyr)
library(Metrics)
library(penalized)
library(gbm)
library(ggthemes)
library(knitr)

path <- getwd()
filename <- "diamonds_data.csv"
fullpath <- file.path(path, filename)
diamonds <- read.csv(fullpath)
rm(path, filename, fullpath)
```

# 2. Methods and Analysis

## Modifying the dataset

If we look at the dataset, we can see that the variables *cut*, *color*, and *clarity* have character values.

```{r, include=TRUE, echo=FALSE}
head(diamonds)
```

If we want to use them for predictions, we need to convert them to numerical (*cut* will be measured from 0 to 4 instead of Fair to Ideal, *color* will be measured from 0 to 6 instead of J to D, *clarity* will be measured from 0 to 7 instead of I1 to IF). After the changes the dataset looks like this.

```{r, include=FALSE}
# Changing the 'cut' to numerical
diamonds$cut[diamonds$cut == "Fair"] = 0
diamonds$cut[diamonds$cut == "Good"] = 1
diamonds$cut[diamonds$cut == "Very Good"] = 2
diamonds$cut[diamonds$cut == "Premium"] = 3
diamonds$cut[diamonds$cut == "Ideal"] = 4
diamonds$cut = as.numeric(diamonds$cut)

# Changing the 'color' to numerical
diamonds$color[diamonds$color == "J"] = 0
diamonds$color[diamonds$color == "I"] = 1
diamonds$color[diamonds$color == "H"] = 2
diamonds$color[diamonds$color == "G"] = 3
diamonds$color[diamonds$color == "F"] = 4
diamonds$color[diamonds$color == "E"] = 5
diamonds$color[diamonds$color == "D"] = 6
diamonds$color = as.numeric(diamonds$color)

# Changing the 'clarity' to numerical
diamonds$clarity[diamonds$clarity == "I1"] = 0
diamonds$clarity[diamonds$clarity == "SI2"] = 1
diamonds$clarity[diamonds$clarity == "SI1"] = 2
diamonds$clarity[diamonds$clarity == "VS2"] = 3
diamonds$clarity[diamonds$clarity == "VS1"] = 4
diamonds$clarity[diamonds$clarity == "VVS2"] = 5
diamonds$clarity[diamonds$clarity == "VVS1"] = 6
diamonds$clarity[diamonds$clarity == "IF"] = 7
diamonds$clarity = as.numeric(diamonds$clarity)
```
```{r, include=TRUE, echo=FALSE}
head(diamonds)
```

Also, a diamond can have various dimensions, but still have the same price, so it is hard to predict the price based on them. That is why we are not going to use them. After taking away *x*, *y*, and *z*, the data looks like this.

```{r, include=FALSE}
diamonds <- diamonds %>% select(carat, cut, color, clarity, depth, table, price)
```
```{r, include=TRUE, echo=FALSE}
head(diamonds)
```

## Building the models

### Splitting the data

The data will be split into train and test sets (90/10). We don't need a lot of testing data, so only 10% will be taken to maximize the training set.

```{r, include=FALSE}
set.seed(1, sample.kind="Rounding")
test_index <- createDataPartition(y = diamonds$price, times = 1, p = 0.1, list = FALSE)
train <- diamonds[-test_index,]
test <- diamonds[test_index,]
```

### Model 1: A first naive "mean" model

To start with, let's create a model that would just predict the mean price for every diamond. The MAPE for that model can be seen below.

```{r, include=TRUE, echo=FALSE}
m <- mean(train$price)
model1_mape <- 100 * mape(test$price, m)
model1_mape
```

Let's create a table, where we will keep all the results and add the results of the first model to the table.

```{r, echo=FALSE}
mape_results <- tibble(Index = "1", Method = "Just the average", MAPE = paste(signif(model1_mape, 4), "%"))
kable(mape_results, caption="MAPE Results Model 1")
```

### Model 2: Linear model, Carat

Let's plot the data for *carat* vs *price*.

```{r, echo=FALSE}
train %>% ggplot(aes(carat, price)) + geom_point()
```

We can see that the carat has an effect on the price. So we will create a linear model that will use the *carat* variable to predict the price of the diamond.

```{r, echo=FALSE}
model_lm_1 <- lm(price ~ carat, data = train)
predictions_lm_1 <- predict(model_lm_1, test)
model2_mape <- 100 * mape(test$price, predictions_lm_1)
```

The MAPE for this model can be seen below.

```{r, echo=FALSE}
model2_mape
```

Let's add it to the table.

```{r, echo=FALSE}
mape_results <- bind_rows(mape_results, tibble(Index = "2", Method="Carat Effect Model", MAPE = paste(signif(model2_mape, 4), "%")))
kable(mape_results, caption="MAPE Results Models 1-2")
```

### Model 3: Linear model, Cut

Let's plot the data for *cut* vs *price* and set alpha to 0.05 so we can see the effect better.

```{r, echo=FALSE}
train %>% ggplot(aes(cut, price)) + geom_point(alpha = 0.05)
```

We can see that the carat has some effect on the price. Diamonds with higher prices tend to have better cuts. So we will add the *cut* as a predictor to our linear model.

```{r, echo=FALSE}
model_lm_2 <- lm(price ~ carat + cut, data = train)
predictions_lm_2 <- predict(model_lm_2, test)
model3_mape <- 100 * mape(test$price, predictions_lm_2)
```

The MAPE for this model can be seen below.

```{r, echo=FALSE}
model3_mape
```

Let's add it to the table.

```{r, echo=FALSE}
mape_results <- bind_rows(mape_results, tibble(Index = "3", Method="Carat + Cut Effect Model", MAPE = paste(signif(model3_mape, 4), "%")))
kable(mape_results, caption="MAPE Results Models 1-3")
```

### Model 4: Linear model, Color

Let's plot the data for *color* vs *price* and set alpha to 0.05 so we can see the effect better.

```{r, echo=FALSE}
train %>% ggplot(aes(color, price)) + geom_point(alpha = 0.05)
```

We can see that the carat has some effect on the price. The diamond prices are not uniformly distributed among colors. So we will add the *color* as a predictor to our linear model.

```{r, echo=FALSE}
model_lm_3 <- lm(price ~ carat + cut + color, data = train)
predictions_lm_3 <- predict(model_lm_3, test)
model4_mape <- 100 * mape(test$price, predictions_lm_3)
```

The MAPE for this model can be seen below.

```{r, echo=FALSE}
model4_mape
```
Let's add it to the table.

```{r, echo=FALSE}
mape_results <- bind_rows(mape_results, tibble(Index = "4", Method="Carat + Cut + Color Effect Model", MAPE = paste(signif(model4_mape, 4), "%")))
kable(mape_results, caption="MAPE Results Models 1-4")
```

### Models 5-7: Linear models, Clarity, Depth, Table

Let's try to add the remaining variables (Clarity, Depth, Table) to our models one by one to see how MAPE would change.

```{r, echo=FALSE}
model_lm_4 <- lm(price ~ carat + cut + color + clarity, data = train)
predictions_lm_4 <- predict(model_lm_4, test)
model5_mape <- 100 * mape(test$price, predictions_lm_4)

model_lm_5 <- lm(price ~ carat + cut + color + clarity + depth, data = train)
predictions_lm_5 <- predict(model_lm_5, test)
model6_mape <- 100 * mape(test$price, predictions_lm_5)

model_lm_6 <- lm(price ~ carat + cut + color + clarity + depth + table, data = train)
predictions_lm_6 <- predict(model_lm_6, test)
model7_mape <- 100 * mape(test$price, predictions_lm_6)
```

The MAPE for the models can be seen below.

```{r, echo=FALSE}
model5_mape
model6_mape
model7_mape
```

Let's add them to the table.

```{r, echo=FALSE}
mape_results <- bind_rows(mape_results, tibble(Index = "5", Method="Carat + Cut + Color + Clarity Effect Model", MAPE = paste(signif(model5_mape, 4), "%")))
mape_results <- bind_rows(mape_results, tibble(Index = "6", Method="Carat + Cut + Color + Clarity + Depth Effect Model", MAPE = paste(signif(model6_mape, 4), "%")))
mape_results <- bind_rows(mape_results, tibble(Index = "7", Method="Carat + Cut + Color + Clarity + Depth + Table Effect Model", MAPE = paste(signif(model7_mape, 4), "%")))
kable(mape_results, caption="MAPE Results Models 1-7")
```

If we look at our results, we see that all the variables added after cut only decreased the accuracy of our model. Looks like linear models aren't the best for this dataset.

### Model 8: KNN model

Let's create a KNN model that would predict the price using the neighbouring points.

```{r knn, echo=FALSE, message = FALSE, warning = FALSE}
set.seed(1, sample.kind="Rounding")
ctrl <- trainControl(method="repeatedcv",repeats = 3) 
model_knn <- train(price ~ ., data = train, method = "knn", trControl = ctrl, preProcess = c("center","scale"), tuneLength = 20)
knnPredict <- predict(model_knn, newdata = test)
model8_mape <- 100 * mape(test$price, knnPredict)
```

The MAPE for the model can be seen below.

```{r, echo=FALSE}
model8_mape
```

Let's add it to the table.

```{r, echo=FALSE}
mape_results <- bind_rows(mape_results, tibble(Index = "8", Method="KNN Model", MAPE = paste(signif(model8_mape, 4), "%")))
kable(mape_results, caption="MAPE Results Models 1-8")
```

### Model 9: Projection pursuit regression model

While looking through the possible models I can make, I stumbled upon a Projection pursuit regression (PPR) model, which is an extension of additive models and is really similar to a neural network. I decided to try to create one for this dataset.

```{r ppr, echo=FALSE, message = FALSE, warning = FALSE}
model_ppr <- train(price ~ ., method = "ppr", data = train)
predictions_ppr <- predict(model_ppr, test)
model9_mape <- 100 * mape(test$price, predictions_ppr)
```

The MAPE for the model can be seen below.

```{r, echo=FALSE}
model9_mape
```

Let's add it to the table.

```{r, echo=FALSE}
mape_results <- bind_rows(mape_results, tibble(Index = "9", Method="PPR Model", MAPE = paste(signif(model9_mape, 4), "%")))
kable(mape_results, caption="MAPE Results Models 1-9")
```

### Model 10: Gradient boosting

Another method that I found was the gradient boosting, which is a machine learning technique that gives a prediction model in the form of an ensemble of weak prediction models, which are typically decision trees. I creted one for this dataset.

```{r gbm, include=FALSE}
model_gbm <- train(price ~ ., method = "gbm", data = train)
predictions_gbm <- predict(model_gbm, test)
model10_mape <- 100 * mape(test$price, predictions_gbm)
```

The MAPE for the model can be seen below.

```{r, echo=FALSE}
model10_mape
```

Let's add it to the table.

```{r, echo=FALSE}
mape_results <- bind_rows(mape_results, tibble(Index = "10", Method="Gradient Boosting Model", MAPE = paste(signif(model10_mape, 4), "%")))
kable(mape_results, caption="MAPE Results Models 1-10")
```

# Results

The results of all the models can be seen in the table below.

```{r, echo=FALSE}
kable(mape_results, caption="Final Reults")
```

As we can see from the table, linear model was not the best method for this dataset. The best MAPE achieved with linear models is `r model3_mape`. Some of the other methods used, including KNN, PPR, and Gradient Boosting, proved to be more effective in predicting the price of a diamond with the given parameters. The lowest MAPE (`r model10_mape`) was achieved with Gradient Boosting.

# Conclusion

In this project, I used different machine learning methods to predict the price of a diamond. The methods used include linear models, KNN, projection pursuit regression, and gradient boosting. Linear models weren't very effective since after a certain point adding new predictors only increased the MAPE of the model. There was no specific goal for the MAPE achieved, and I think that the MAPEs achieved were low enough. The best model was able to, on average, predict the price within `r model10_mape` percent of the actual price.

One of the biggest limitations was the computation time. For example, some methods like random forests weren't tested since they took too much time to create the models (the time was tested on smaller samples of data).

The future work may include using other machine learning methods to decrease MAPE even further.








